---
layout:     post
title:      "AM-GCN"
subtitle:   "Adaptive Multi-channel Graph Convolutional Networks"
date:       2020-09-04
author:     "wumingyao"
header-img: "img/in-post/2020.09/04/bg.jpg"
tags: [论文笔记,]
categories: [论文笔记]
---

## 主要内容
* [ABSTRACT](#p1)
* [一、INTRODUCTION](#p2)
* [二、Preliminaries](#p3)
* [三、Methodology](#p4)
* [四、EXPERIMENT](#p5)

## 参考论文：
[《AM-GCN:Adaptive Multi-channel Graph Convolutional Networks》](https://dl.acm.org/doi/pdf/10.1145/3394486.3403177)

## 正文

###  <span id="p1">ABSTRACT</span>
#### 任务(Objective)
问题：最近的一些研究提出了GCNs能否在信息丰富的复杂图中最优地集成节点特征和拓扑结构的问题。
#### 方法(Methods)：对研究的基本设计加以描述。
核心思想是从节点特征、拓扑结构及其组合中同时提取特定的和常见的嵌入，并利用注意机制学习嵌入的自适应重要性权重。
#### 结果(Results)
在基准数据集上的大量实验清楚地表明，AM-GCN从节点特征和拓扑结构中提取了最相关的信息，并以明显提高了分类精度

###  <span id="p2">一、INTRODUCTION</span>
#### 研究背景和重要性(Background And Importance)
网络数据很普遍，图卷积网络在处理图数据方面的流行。
典型的GCN及其变体通常遵循消息传递(message-passing)方式。关键步骤是特征聚合，即节点在每个卷积层中聚合来自其拓扑邻居的特征信息。
邻居特征信息通过网络拓扑传递到结点嵌入。
GCNs网络的成功部分归因于GCN提供了在拓扑结构和结点特征上的端到端的融合机制来学习结点的嵌入。
#### 该领域的科研空白/挑战(Description of knowledge gap or chanllenge)
最近的一些研究揭示了最新的GCN在融合节点特征和拓扑结构方面的某些弱点。
GCN无法充分融合节点特征和拓扑结构以提取最相关的信息
#### 本文的研究课题(Topic Of Research Paper)
GCNs融合结点特征和拓扑结构。GCN学习到了以及从拓扑结构和结点特征中融合了哪些信息？
#### 核心方法论和主要发现/结果(Highlight The Approach And Highlight Principal Findings/Result)
提出了一种用于半监督分类的自适应多通道图卷积网络（AM-GCN），该模型的中心思想是基于节点特征，拓扑结构及其组合同时学习节点嵌入。
其基本原里是，结点特征之间的相似性以及由拓扑结构推断出的相似性是相互补充的，可以自适应
地融合以得出用于分类任务地更深层地相关性信息。

1)为了充分利用特征空间中的信息，作者将从结点特征中生成的k个最近邻邻居图做为特征结构图。

2)通过特征图和拓扑图，在拓扑空间和特征空间上传播节点特征，从而使用两个特定的卷积模块在这两个空间中提取两个特定的嵌入。

3)考虑到两个空间之间的共同特征，我们设计了一个具有参数共享策略的公共卷积模块，以提取它们共享的公共嵌入。

4)我们进一步利用注意力机制自动学习不同嵌入的重要性权重，以自适应地融合它们。

5)
###  <span id="p3">二、Preliminaries</span>


#### 问题定义
给定来自路网中相关交通传感器的历史交通数据，交通预测的任务是预测路网的未来交通。
将𝑁个相关交通传感器定义为加权有向图$G=(V,E,A)$，其中，$V$是$|V|=N$个结点的集合，
$E$是边的集合，$A\in \mathbb{R}^{N\times N}$是带权连接矩阵，代表节点之间的距离。
在$t$时刻在图G上的观测数据标记为一个图信号$X^{(t)}\in \mathbb{R}^{N\times P}$，
其中，$P$是每个节点的特征维度（例如，如果只统计节点的流量，那P==1）。

交通预测任务是在给定$T'$历史图信号和图G的情况下，学习一个函数$f$来预测未来$T$个时间片的图信号

$$[X^{(t-T'+1):t},G] \xrightarrow{f} [X^{(t+1):(t+T)}]$$,

其中，$X^{(t-T'+1):t} \in \mathbb{R}^{N\times P\times T'}, X^{(t+1):(t+T)} \in \mathbb{R}^{N\times P\times T}$

#### Graph Convolution
在图$G=(V,E,A)$上定义图卷积

$$\theta_{*G}X=\rho(\tilde{D}^{-1}\tilde{A}X\theta)\tag{1}$$

其中，$X\in\mathbb{R}^{N\times P}$是输入信号，$\theta\in\mathbb{R}^{P\times F}$
是可学习的参数矩阵，$\tilde{A}=A+I_N$是是自连接的邻接矩阵，$\tilde{D}$是$\tilde{A}$
的对角度矩阵。$\tilde{D}^{-1}\tilde{A}$代表规范化邻接矩阵，$\rho$是非线性激活函数。

图卷积可以聚合一跳邻居的信息。 通过堆叠多个图卷积层，我们可以扩展接收邻域范围。
###  <span id="p4">三、Methodology</span>

#### Model Overview
![Figure 2](../../../../../../img/in-post/2020.08/28/Figure 2.jpg)

如图2所示，MRA-BGCN包含两部分：

1) the bicomponent graph convolution module

该部分包含几个node-wise graph convolution layers和edge-wise graph convolution layers，
可以显式地建模节点和边的交互。

2) the multi-range attention layer

该层层聚合了不同邻域范围内的信息，并学习了不同范围内的重要性。

#### Bicomponent Graph Convolution

图卷积是在给定图结构的情况下对节点交互进行建模的有效操作。
但是，在交通预测中，对边交互进行的建模更加复杂。因此，使用Bicomponent Graph Convolution
对节点和边进行显性建模。

陈等人建议引入边缘邻接线图以建模边缘相关性。

$G=(V,E,A)$代表点图，$G_L=(V_L,E_L,A_L)$是相应的线图，$G_L$图中的点$V_L$
是对应的$E$中的边，例如$V_L=\lbrace (i\rightarrow j);(i,j)\in E$并且$|V_L|=|E|$。
$A_L$是无权邻接矩阵，$A_{L,(i\rightarrow j),(j\rightarrow k)}=1,否则为0$
当一个节点做为一条边的起点，并且做为另一条边的终点时，才认为这两条边时相关的。
![Figure 3](../../../../../../img/in-post/2020.08/28/Figure 3.jpg)

如图3所示，定义两种类型的边交互模式来构建edge-wise graph $G_e=(V_e,E_e,A_e)$,
每个点$V_e$代表$E$的一条边。

#### Stream connectivity
在Figure 3(a)中，$(i\rightarrow j)$是$(j\rightarrow k)$的上游边，因此他们是相关联的。
如果结点$j$有大量的邻居，则$(i\rightarrow j)$与$(j\rightarrow k)$之间相关性就比较弱，因为
这条边容易受到其他邻居的影响。
对于stream connectivity的在$A_e$中的边的权重的计算如下：

$$A_{e,(i\rightarrow j),(j\rightarrow k)}=A_{e,(j\rightarrow k),(i\rightarrow j)}=exp(-\frac{(deg^-(j)+deg^+(j)-2)^2}{\sigma ^2})\tag{2}$$ 

其中，$deg^-(j)$和$deg^+(j)$代表结点$j$的出度和入度，$\sigma$是节点度数的标准偏差。

#### Competitive relationship
共享同一个源节点的道路链接可能会争夺交通资源并引发竞争关系。
如Figure 3(b),两条边$i\rightarrow k$和$(j\rightarrow k)$共享目标结点$k$是相关联的，
对于Competitive relationship的在$A_e$中的边的权重的计算如下：

$$A_{e,(i\rightarrow k),(j\rightarrow k)}=A_{e,(j\rightarrow k),(i\rightarrow k)}=exp(-\frac{(deg^+(i)+deg^+(j)-2)^2}{\sigma ^2})\tag{3}$$ 

第k跳的bicomponent graph convolution 公式如下：
![Tag 4](../../../../../../img/in-post/2020.08/28/Tag 4.jpg)

其中$\theta_{*G}$是带有参数$\theta$的图卷积操作，$[\cdot,\cdot]$是连接操作。
$X^{(l-1)}$是node-wise图卷积$l$层的输入，$Z^{(l-1)}$是edge-wise图卷积$l$
层的输入。$M\in \mathbb{R}^{|V|\times|E|}$是入射矩阵，定义为$M_{i,(i\rightarrow j)}=M_{j,(i\rightarrow j)}=1$否则为0.
$MZ^{(\cdot)}$聚合与每个单个节点连接的边表示,
$M^TX^{(\cdot)}$聚合与每个单边连接的节点表示。
$W_b$是一个可学习的投影矩阵，它将原始节点输入$X^{(0)}$转换为原始边缘输入$Z^{(0)}$。

#### Multi-Range Attention 
我们为双分量图卷积提出了多范围注意机制，以自动了解不同邻域范围的重要性，该功能仅能够汇总不同邻域范围内的信息，而不仅仅是给定邻域范围（即𝑘跳内的邻居）的信息。

双成分图卷积包含不同邻居范围内的点表示，$\chi=\lbrace X^{(1)},X^{(2)},\cdots,X^{(k)},X^{(l)}\in\mathbb{R}^{\vert V \vert\times F}$，
其中，$k$是最大的跳，$F$是每个结点的特征维度，$X_i^{(l)}\in\mathbb{R}^F$表示结点$i$在
$l$层的表示。多范围关注层旨在捕获来自多个邻域范围的集成表示。
为此，首先，将由$W_a\in \mathbb{R}^{F\times F'}$参数化的共享线性变换应用于每层中的每个节点。
通过计算$W_aX_i^{(l)}$和$u$的相似度来测量注意力协方差，其中$u\in\mathbb{R}^{F'}$是
邻居范围内容嵌入。最后，使用SoftMax函数对系数进行归一化。 多范围注意力机制被表述为：
![Tag 5](../../../../../../img/in-post/2020.08/28/Tag 5.jpg)
一旦获得归一化的注意力系数，我们将为每个节点计算每一层中表示的线性组合，如下所示：

$$h_i=\sum^{k}_{l=1}a_i^{l}X_i^{(l)}\tag{6}$$
#### Bicomponent Graph Convolutional RNN 
我们将此RNN结构称为双分量图卷积GRU（BGCGRU）。
为了简化公式，我们将$g(X;\theta)$表示为将MRA-BGCN应用于输入$X$，$\theta$是
所有可训练的参数。BGCGRU公式为：
![Tag 7](../../../../../../img/in-post/2020.08/28/Tag 7.jpg)
其中，$X^{(t)}$和$H^{(t)}$代表在时间步$t$的输入和输出，$z^{(t)}$和$r^{(t)}$
表示在时间步$t$的更新门和重置门，$\sigma$是Sigmoid函数，$\bigodot$是Hadamard 乘积。
![Figure 4](../../../../../../img/in-post/2020.08/28/Figure 4.jpg)
如图4所示，我们堆叠了多个BGCGRU层，并采用Sequence to Sequence架构进行多步流量预测。
###  <span id="p5">四、EXPERIMENT</span>
#### Experimental Settings 
该任务是学习一个函数$f:\mathbb{R}^{N\times P\times T'}\rightarrow\mathbb{R}^{N\times P\times T}$。
在该实验中，$T=T'=12$，BGCGRU的层数是2，带有64个隐藏单元。最大跳数$k$设置为3.
使用Adam优化器进行训练，使用MAE做为监测指标，epochs=100,batch_size=64。
初始学习率为le-2,每10个epochs衰减率为0.6。

#### Effect of the Edge-Wise Graph
为了验证edge-wise graph的有效性，将MRA-BGCN与两个变体进行比较：
1) MRA-BGCN-Identity,该变体忽略边的相关性，并且使用一个单位矩阵来取代边的邻接矩阵。
从本质上讲，这意味着边不会互相影响，而仅由连接的节点确定。
2) MRA-BGCN-LineGraph,该变体使用line graph来取代edge-wise graph，line graph忽略了各种边交互模式。
通过表3可以看处Edge-wise Graph的有效性。直觉是，所提出的Edge-wise Graph考虑了流的连通性和竞争关系，并使模型具有捕获复杂依赖性的能力。
![Table 3](../../../../../../img/in-post/2020.08/28/Table 3.jpg)

#### Effect of the Multi-Range Attention Mechanism
为了进一步验证multi-range attention 机制的有效性，作者验证了MRA-BGCN和
使用不同方法来利用多范围信息的两个变体的性能。
1) BGCN,biocomponent graph convolutional network,该网络忽略多范围信息并使用在给定邻域范围内聚合的表示形式（即仅使用第𝑘层的输出）;
2)  MR-BGCN, multi-range bicomponent graph convolutional network,该网络通过在每一层中连接表示来利用多范围信息，并认为来自每个邻域范围的信息都做出了同等贡献。
表4可以看出Multi-Range Attention机制的有效性。

![Table 4](../../../../../../img/in-post/2020.08/28/Table 4.jpg)

![Figure 5](../../../../../../img/in-post/2020.08/28/Figure 5.jpg)

